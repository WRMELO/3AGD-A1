# CHECKPOINT DE ETAPA ‚Äì PROJETO OVATION

## üìç Identifica√ß√£o
- **Etapa:** 1 ‚Äì Planejamento para carregamento e verifica√ß√£o dos arquivos
- **Data/Hora:** 08/08/2025 - 18:58
- **Respons√°vel:** [Usu√°rio]
- **Protocolo ativo:** PROTOCOLOS_UNIFICADOS_V2.md
- **MODO ULTRA-HF-000:** ATIVADO

---

## üìÑ Contexto t√©cnico
Definido o plano detalhado para execu√ß√£o da Etapa 1, que consiste no carregamento e verifica√ß√£o dos arquivos `ovation_dados_curado.csv` e `campos_formatados-simples.csv`.  
O objetivo √© confirmar a estrutura, consist√™ncia e integridade dos dados antes de criar o mapeamento de colunas.  
Nenhuma leitura, escrita ou modifica√ß√£o ser√° feita neste momento pela IA ‚Äî apenas fornecimento de c√≥digo para execu√ß√£o no ambiente local do usu√°rio.

---

## üìÇ Arquivos envolvidos
1. `ovation_dados_curado.csv` ‚Äì CSV com 154 colunas (`col_001` at√© `col_154`), dados curados.
2. `campos_formatados-simples.csv` ‚Äì CSV com descri√ß√µes e unidades das vari√°veis, base para criar `nome_curto` e `nome_curto_com_unidade`.

---

## ‚úÖ Valida√ß√µes conclu√≠das
- [x] Escopo e estrutura dos arquivos definidos.
- [x] Plano de valida√ß√£o documentado.
- [x] Restri√ß√µes de protocolo aplicadas.
- [ ] Estrutura real dos arquivos confirmada (pendente execu√ß√£o local pelo usu√°rio).
- [ ] N√∫mero real de colunas/linhas verificado (pendente execu√ß√£o local pelo usu√°rio).
- [ ] Presen√ßa das colunas essenciais (`descricao_limpa`, `unidade_padrao`) confirmada (pendente execu√ß√£o local pelo usu√°rio).

---

## ‚ö†Ô∏è Restri√ß√µes aplic√°veis
- Nenhuma execu√ß√£o no ambiente da IA.
- Nenhuma modifica√ß√£o no dataset original.
- Nenhuma infer√™ncia autom√°tica.
- Somente decis√µes validadas com evid√™ncia objetiva.

---

## üîú Pr√≥xima a√ß√£o planejada
Execu√ß√£o local do c√≥digo de leitura e verifica√ß√£o da estrutura dos dois arquivos, conforme plano definido:
1. Carregar `ovation_dados_curado.csv` e confirmar que cont√©m exatamente 154 colunas.
2. Carregar `campos_formatados-simples.csv` e confirmar que cont√©m no m√≠nimo 154 linhas.
3. Validar presen√ßa das colunas `descricao_limpa` e `unidade_padrao`.
4. Exibir amostras iniciais (5 primeiras colunas do primeiro arquivo e 5 primeiras linhas do segundo).

---

## üóí Observa√ß√µes adicionais
- Etapa 1 √© exclusivamente de valida√ß√£o; qualquer cria√ß√£o de mapeamento (`df_nomes_colunas`) s√≥ ser√° feita na Etapa 2, ap√≥s aprova√ß√£o.
- Este checkpoint pode ser usado como ponto oficial de retomada caso haja pausa prolongada.

# ‚úÖ CHECKPOINT ‚Äì FECHAMENTO DA ETAPA DE ENGENHARIA DE NOMES E ESTRUTURA√á√ÉO INICIAL

**Data de registro:** (preencher manualmente)  
**Respons√°vel:** (preencher manualmente)  
**Pipeline:** A1 ‚Äì Curadoria T√©cnica de Vari√°veis e Estrutura√ß√£o Sem√¢ntica  
**Notebook de origem:** `a1_engenharia_dados.ipynb` (in√≠cio oficial)

---

## üîπ OBJETIVO DA ETAPA

Padronizar, corrigir e consolidar os dados t√©cnicos da opera√ß√£o da caldeira CFB para uso futuro em modelagem de desgaste (`Wr`, `Wm`), an√°lise explorat√≥ria e projetos de previs√£o com IA (ML/DL).

---

## üî∏ RESULTADOS CONSOLIDADOS

### üìÅ Arquivos Gerados

1. **`ovation_dados_curado_v2_com_nomes.csv`**  
   - Dados totalmente corrigidos (alinhamento de colunas, corre√ß√£o de headers, nomes curtos).
   - Coluna `datahora` validada e padronizada.
   - Refer√™ncia segura para segmenta√ß√µes e sele√ß√£o de blocos futuros.

2. **`dados_para_cura.csv`**  
   - Subconjunto segmentado de dados com foco em curadoria e engenharia inicial.
   - Cont√©m colunas com nomes curtos + `datahora`.

3. **`ovation_mapeado_nome_unidade_classificado_v2.csv`**  
   - Dicion√°rio estendido com as colunas:
     - `point_name`, `descricao`, `unidade`
     - `nome_curto_com_unidade` (chave de liga√ß√£o)
     - `categoria` (`operacao_direta` ou `consequencia`)
     - `wr_wm_role` (manual, ainda n√£o validado)
     - `wr_wm_role_heuristica` (auto-sugerido)

---

## üß† L√ìGICA ADOTADA

### 1. `tipo_variavel`  
Classifica√ß√£o em:
- `operacao_direta`: Vari√°veis manipuladas diretamente pela opera√ß√£o (ex.: vaz√µes, setpoints, velocidades).
- `consequencia`: Vari√°veis que refletem o comportamento do sistema (ex.: temperaturas, press√µes medidas).

Crit√©rios:
- Regras objetivas com base em nomes e unidades (ex.: `t/h`, `Nm3/h`, `rpm`).

### 2. `wr_wm_heuristica`  
Classifica√ß√£o heur√≠stica autom√°tica com base em substrings e padr√µes no nome da vari√°vel:
- Ex: `bed_temp`, `coal_flow`, `recirc`, `o2`, `dp`, `steam_flow`, `emission`, `rpm`, etc.
- Categoria `unknown` atribu√≠da quando nenhum padr√£o √© identificado.

---

## üßæ A√á√ïES FUTURAS (PR√â-PLANEJADAS)

- Gera√ß√£o da vers√£o `dados_para_cura_header3.csv`, com 3 linhas de cabe√ßalho:
  1. Cabe√ßalho original (nomes curtos)
  2. Linha `tipo_variavel`
  3. Linha `wr_wm_heuristica`

- Cria√ß√£o do notebook `a1_eda.ipynb` com:
  - Estat√≠sticas descritivas
  - Valida√ß√£o da coer√™ncia entre classifica√ß√µes
  - Sele√ß√£o inicial de candidatos a vari√°veis explicativas

---

## ‚öôÔ∏è STATUS DE ETAPA

‚úÖ Etapa encerrada e validada. Pronto para seguir para **EDA + defini√ß√£o de proxy de desgaste (Wr/Wm)**.  
Nenhum erro estrutural ou sem√¢ntico pendente nos dados atuais.

---
Segue o **checkpoint** formatado no padr√£o de registro para o seu Obsidian, documentando a decis√£o de modelo de salvamento adotado.

---

## **CHECKPOINT ‚Äì MODELO DE SALVAMENTO DE DADOS DE OPERA√á√ÉO**

**Data:** 2025-08-09  
**Projeto:** A1 ‚Äì Opera√ß√£o e Paradas  
**Respons√°vel:** Wilson Melo  
**Status:** Aprovado e implementado

---

### **1. Contexto**

Durante o tratamento e segmenta√ß√£o dos dados de opera√ß√£o, definimos um crit√©rio √∫nico para classificar o status de cada ponto temporal:

- **Em opera√ß√£o normal (1):** `flw_total_c_t_h > 40`
    
- **Fora de opera√ß√£o normal (0):** `flw_total_c_t_h <= 40` ou valores `NaN`
    

Esse crit√©rio substituiu os anteriores e passou a ser **regra √∫nica** para qualquer derivado.

---

### **2. Modelo de Salvamento**

Foi adotado um modelo **h√≠brido** de persist√™ncia:

1. **Arquivo consolidado**:
    
    - Nome: `dados_operacao_consolidado.csv`
        
    - Cont√©m **todas as observa√ß√µes** (opera√ß√£o normal e fora de opera√ß√£o normal), com coluna `status_operacao` (`1` ou `0`) para filtragem futura.
        
    - Serve como **√∫nica fonte de verdade** para deriva√ß√µes.
        
2. **Arquivos derivados** (gerados automaticamente a partir do consolidado):
    
    - `dados_em_operacao_normal.csv` ‚Üí apenas registros com `status_operacao == 1`.
        
    - `dados_fora_operacao_normal.csv` ‚Üí apenas registros com `status_operacao == 0`.
        
    - Facilitam an√°lises e gr√°ficos sem necessidade de filtro manual.
        
3. **Arquivo de auditoria**:
    
    - `resumo_split_operacao.csv` ‚Üí resumo de contagem e propor√ß√£o de cada classe, validando se os derivados batem com os valores do consolidado.
        

---

### **3. Estrutura de Pastas**

```
A1_LOCAL/
  data/
    staged/
      dados_operacao_consolidado.csv
      dados_em_operacao_normal.csv
      dados_fora_operacao_normal.csv
      resumo_split_operacao.csv
      antigos/  ‚Üê backups de vers√µes anteriores
```

---

### **4. Regras de Opera√ß√£o**

- O consolidado **nunca √© sobrescrito manualmente** ‚Äî apenas via pipeline definido.
    
- Arquivos anteriores ao consolidado s√£o movidos para `staged/antigos/`.
    
- Qualquer nova deriva√ß√£o parte exclusivamente do consolidado.
    
- O `status_operacao` √© calculado sempre via **limiar fixo de 40 t/h** em `flw_total_c_t_h`.
    

---

### **5. Pr√≥ximos Passos**

- Utilizar `dados_em_operacao_normal.csv` para an√°lises de performance e varia√ß√£o interna.
    
- Utilizar `dados_fora_operacao_normal.csv` para an√°lises de paradas e eventos cr√≠ticos.
    
- Manter registro de cada atualiza√ß√£o do consolidado neste mesmo formato no Obsidian.
    

---


---

## **Checkpoint ‚Äì Estado Atual do Projeto A1 (Predi√ß√£o de Desgaste CFB)**

### **Base e Estrutura**

- Arquivo atual de trabalho:  
    `dados_operacao_consolidado_dimcorrigida.csv`  
    (local: `data/staged/`)
    
- Colunas **protegidas**:
    
    - Timestamp (coluna original `Timestamp`, preservando mai√∫scula inicial)
        
    - `status_operacao`
        
    - `flw_total_a_t_h`
        
    - `flw_total_b_t_h`
        
    - `flw_total_c_t_h`
        
- Dimens√£o f√≠sica extra√≠da a partir do sufixo do nome curto (ex.: `kpa`, `adegc`, `nm3_h`, `%`).
    
- Indicadores ‚Äúsem dimens√£o‚Äù tratados como `%` quando aplic√°vel.
    
- Prefixos de **parciais** conhecidos (`flw_output_of_belt_coal_fdr_`) s√£o removidos antes do agrupamento.
    

### **Objetivo Atual**

Aplicar **redu√ß√£o de cardinalidade com consist√™ncia dimensional**, usando:

- Correla√ß√£o de Pearson absoluta por dimens√£o.
    
- Limite: **|r| ‚â• 0,90**.
    
- Para cada grupo correlacionado:
    
    - Criar vari√°veis **m√©dia** (`mean_<dim>_Gxxx`) e **desvio padr√£o** (`std_<dim>_Gxxx`).
        
    - Remover as colunas originais do grupo, exceto as protegidas.
        
- Garantir que totais A/B/C **nunca sejam removidos**.
    
- Preservar ordem final: Timestamp no in√≠cio, `status_operacao` no fim.
    

### **Sa√≠das Definidas**

Todos os arquivos v√£o para `output/eda/`:

- `correlacoes_<dim>.csv` ‚Üí Matriz de correla√ß√£o absoluta por dimens√£o.
    
- `mapa_grupos_<dim>.csv` ‚Üí Mapeamento de grupos correlacionados.
    
- `curado_dimensional.csv` ‚Üí Dataset final √∫nico reduzido (base para curated).
    
- `resumo_correlacoes_por_dimensao.csv` ‚Üí Estat√≠sticas de redu√ß√£o por dimens√£o.
    

### **Status da Execu√ß√£o**

- C√≥digo revisado e ajustado para:
    
    - Remover parciais antes do c√°lculo.
        
    - Proteger vari√°veis essenciais.
        
    - Evitar erros por colunas duplicadas ou j√° removidas.
        
- √öltima a√ß√£o: C√≥digo final montado para execu√ß√£o completa da redu√ß√£o com consist√™ncia dimensional.
    
- Pr√≥xima etapa: Rodar o script para gerar as sa√≠das finais.
    

---

Se usarmos este checkpoint, o pr√≥ximo chat come√ßa **diretamente na execu√ß√£o da redu√ß√£o** e gera√ß√£o dos arquivos de sa√≠da, sem necessidade de relembrar decis√µes anteriores.

Quer que eu j√° salve esse checkpoint tamb√©m em formato **Markdown para download**?